# to start launch spark job
#HBase Batch
~/spark-1.5.1-bin-hadoop2.4/bin/spark-submit --class fr.finaxys.tutorials.utils.spark.batch.HBaseAnalysis target/hadoop-tutorial-0.2-SNAPSHOT-jar-with-dependencies.jar
#Streaming HBase
~/spark-1.5.1-bin-hadoop2.4/bin/spark-submit --class fr.finaxys.tutorials.utils.spark.streaming.HBaseStreamingAnalysis target/hadoop-tutorial-0.2-SNAPSHOT-jar-with-dependencies.jar
#Parquet Batch
~/spark-1.5.1-bin-hadoop2.4/bin/spark-submit --class fr.finaxys.tutorials.utils.spark.batch.ParquetAnalysis target/hadoop-tutorial-0.2-SNAPSHOT-jar-with-dependencies.jar
#Spark with yarn 
spark-submit --num-executors 20 --driver-memory 12g --executor-cores 6 --master yarn-client
#cluster command 
/home/finaxys/spark-1.5.2-bin-hadoop2.6/bin/spark-submit --class fr.finaxys.tutorials.utils.spark.batch.ParquetAnalysis target/hadoop-tutorial-0.2-SNAPSHOT-jar-with-dependencies.jar
#cluster yarn command
/home/finaxys/spark-1.5.2-bin-hadoop2.6/bin/spark-submit --num-executors 20 --driver-memory 12g --executor-cores 6 --master yarn-client  --class fr.finaxys.tutorials.utils.spark.batch.ParquetAnalysis target/hadoop-tutorial-0.2-SNAPSHOT-jar-with-dependencies.jar
